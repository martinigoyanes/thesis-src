You have the following GPUs: [6]
JOB:  364454
TASK: 
HOST: rivendell.rpl

Fri Mar 10 13:07:12 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:3E:00.0 Off |                  N/A |
| 27%   28C    P8     3W / 250W |      1MiB / 11019MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Some weights of OpenAIGPTLMHeadModel were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['position_ids']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[rank: 0] Global seed set to 44
/Midgard/home/martinig/miniconda3/envs/thesis-src/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:166: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python code/train_gst.py --batch_size 32 --datamodule_name  ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
03/10/2023 13:07:39 - INFO - datasets -   Loading train tokenization from cache [/Midgard/home/martinig/thesis-src/data/yelp/bert_best_head_removal/.cache/sentiment.train.tokenized.pt] ...
03/10/2023 13:08:10 - INFO - datasets -   Loading dev tokenization from cache [/Midgard/home/martinig/thesis-src/data/yelp/bert_best_head_removal/.cache/sentiment.dev.tokenized.pt] ...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loading `train_dataloader` to estimate number of stepping batches.
/Midgard/home/martinig/miniconda3/envs/thesis-src/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 48 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/Midgard/home/martinig/miniconda3/envs/thesis-src/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(

  | Name  | Type                 | Params
-----------------------------------------------
0 | model | OpenAIGPTLMHeadModel | 116 M 
-----------------------------------------------
116 M     Trainable params
0         Non-trainable params
116 M     Total params
466.158   Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.34s/it]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.69s/it]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/20 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s] Epoch 0:   5%|â–Œ         | 1/20 [00:21<06:45, 21.35s/it]Epoch 0:   5%|â–Œ         | 1/20 [00:21<06:45, 21.36s/it, loss=4.29, v_num=364454, train_loss_step=4.290]Epoch 0:  10%|â–ˆ         | 2/20 [00:21<03:14, 10.80s/it, loss=4.29, v_num=364454, train_loss_step=4.290]Epoch 0:  10%|â–ˆ         | 2/20 [00:21<03:14, 10.81s/it, loss=3.84, v_num=364454, train_loss_step=3.380]Epoch 0:  15%|â–ˆâ–Œ        | 3/20 [00:21<02:03,  7.29s/it, loss=3.84, v_num=364454, train_loss_step=3.380]Epoch 0:  15%|â–ˆâ–Œ        | 3/20 [00:21<02:03,  7.29s/it, loss=3.56, v_num=364454, train_loss_step=3.010]Epoch 0:  20%|â–ˆâ–ˆ        | 4/20 [00:22<01:28,  5.53s/it, loss=3.56, v_num=364454, train_loss_step=3.010]Epoch 0:  20%|â–ˆâ–ˆ        | 4/20 [00:22<01:28,  5.53s/it, loss=3.32, v_num=364454, train_loss_step=2.600]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:22<01:07,  4.47s/it, loss=3.32, v_num=364454, train_loss_step=2.600]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:22<01:07,  4.47s/it, loss=3.23, v_num=364454, train_loss_step=2.900]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:22<00:52,  3.77s/it, loss=3.23, v_num=364454, train_loss_step=2.900]Epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:22<00:52,  3.77s/it, loss=3.17, v_num=364454, train_loss_step=2.860]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:22<00:42,  3.27s/it, loss=3.17, v_num=364454, train_loss_step=2.860]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:22<00:42,  3.27s/it, loss=3.07, v_num=364454, train_loss_step=2.490]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:23<00:34,  2.89s/it, loss=3.07, v_num=364454, train_loss_step=2.490]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:23<00:34,  2.89s/it, loss=3, v_num=364454, train_loss_step=2.500]   Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:23<00:28,  2.60s/it, loss=3, v_num=364454, train_loss_step=2.500]Epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:23<00:28,  2.60s/it, loss=2.95, v_num=364454, train_loss_step=2.530]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:23<00:23,  2.36s/it, loss=2.95, v_num=364454, train_loss_step=2.530]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:23<00:23,  2.36s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|â–ˆ         | 1/10 [00:00<00:00, 50.42it/s][AEpoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:49<00:40,  4.53s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:00, 27.70it/s][AEpoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:49<00:33,  4.15s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:00<00:00, 24.08it/s][AEpoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:49<00:26,  3.84s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:00<00:00, 23.03it/s][AEpoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:49<00:21,  3.57s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:00<00:00, 22.93it/s][AEpoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:49<00:16,  3.33s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:00<00:00, 22.82it/s][AEpoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:50<00:12,  3.13s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:00<00:00, 22.67it/s][AEpoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:50<00:08,  2.95s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:00<00:00, 22.53it/s][AEpoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:50<00:05,  2.79s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:00<00:00, 22.24it/s][AEpoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:50<00:02,  2.64s/it, loss=2.92, v_num=364454, train_loss_step=2.690]
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 22.23it/s][AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:50<00:00,  2.51s/it, loss=2.92, v_num=364454, train_loss_step=2.690]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:50<00:00,  2.51s/it, loss=2.92, v_num=364454, train_loss_step=2.690, val_loss_step=2.540, val_loss_epoch=2.550]
                                                                        [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:50<00:00,  2.51s/it, loss=2.92, v_num=364454, train_loss_step=2.690, val_loss_step=2.540, val_loss_epoch=2.550, train_loss_epoch=2.920]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:57<00:00,  2.89s/it, loss=2.92, v_num=364454, train_loss_step=2.690, val_loss_step=2.540, val_loss_epoch=2.550, train_loss_epoch=2.920]
